import dashscope
import pandas as pd
import re
import time
import streamlit as st
import matplotlib.pyplot as plt
from rapidfuzz import fuzz, process
from dashscope import Generation
from collections import deque
import os
import matplotlib

try:
    # å°è¯•ä½¿ç”¨ç³»ç»Ÿä¸­å¯èƒ½æœ‰çš„ä¸­æ–‡å­—ä½“
    system_fonts = matplotlib.font_manager.get_font_names()
    chinese_fonts = ['SimHei', 'Microsoft YaHei', 'SimSun', 'KaiTi', 'FangSong', 'STXihei', 'STKaiti', 'STSong']

    available_font = None
    for font in chinese_fonts:
        if font in system_fonts:
            available_font = font
            break

    if available_font:
        plt.rcParams['font.sans-serif'] = [available_font]
        plt.rcParams['axes.unicode_minus'] = False
        print(f"ä½¿ç”¨ä¸­æ–‡å­—ä½“: {available_font}")
    else:
        # å¦‚æœæ²¡æœ‰ä¸­æ–‡å­—ä½“ï¼Œå°è¯•æ·»åŠ 
        print("æœªæ‰¾åˆ°ç³»ç»Ÿä¸­æ–‡å­—ä½“ï¼Œå°è¯•å…¶ä»–æ–¹æ³•...")
        # ä½¿ç”¨é»˜è®¤å­—ä½“ï¼Œä½†å¯èƒ½æ˜¾ç¤ºä¸ºæ–¹å—

except Exception as e:
    print(f"è®¾ç½®ä¸­æ–‡å­—ä½“æ—¶å‡ºé”™: {e}")

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ·˜å®å®¢æœAIåŠ©æ‰‹æ¼”ç¤º",
    page_icon="ğŸ¤–",
    layout="wide"
)

# åˆå§‹åŒ–Session State
if 'history' not in st.session_state:
    st.session_state.history = deque(maxlen=3)  # å¯¹è¯å†å²çª—å£
if 'all_conversations' not in st.session_state:
    st.session_state.all_conversations = []  # å®Œæ•´å¯¹è¯è®°å½•
if 'knowledge_df' not in st.session_state:
    st.session_state.knowledge_df = None  # ç»Ÿä¸€çŸ¥è¯†åº“DataFrame
if 'rule_base' not in st.session_state:
    st.session_state.rule_base = None  # è§„åˆ™åº“ï¼ˆä»…ç”¨äºæ„å›¾è¯†åˆ«ï¼‰


def desensitize(text):
    """åŠ¨æ€è„±æ•å‡½æ•°ï¼šéƒ¨åˆ†é®è”½ï¼Œä¿ç•™ä¿¡æ¯å¯ç”¨æ€§"""
    if not isinstance(text, str):
        return text

    # 1. æ‰‹æœºå· - ä½¿ç”¨å‰åæ–­è¨€ç¡®ä¿æ˜¯ç‹¬ç«‹çš„11ä½æ•°å­—
    phone_pattern = r'(?<!\d)(1[3-9]\d{2})\d{4}(\d{3})(?!\d)'
    text = re.sub(phone_pattern, r'\1****\2', text)

    # 2. èº«ä»½è¯å· - 18ä½ï¼Œä½¿ç”¨å‰åæ–­è¨€
    id_card_pattern = r'(?<!\d)([1-9]\d{5})\d{8}([\dXx]{4})(?!\d)'
    text = re.sub(id_card_pattern, r'\1********\2', text)

    # 3. è®¢å•å· - å¯å˜é•¿åº¦ï¼Œä½†è‡³å°‘7ä½ï¼Œç¡®ä¿å‰åä¸æ˜¯æ•°å­—
    # é¿å…åŒ¹é…åˆ°æ‰‹æœºå·æˆ–èº«ä»½è¯å·
    order_pattern = r'(?<!\d)(\d{3})\d+(\d{4})(?!\d)'
    text = re.sub(order_pattern, r'\1****\2', text)

    # 4. é‚®æ”¿ç¼–ç  - 6ä½æ•°å­—ï¼Œå‰åä¸æ˜¯æ•°å­—
    zip_code_pattern = r'(?<!\d)(\d{2})\d{2}(\d{2})(?!\d)'
    text = re.sub(zip_code_pattern, r'\1**\2', text)

    # 5. é‚®ç®± - å‰åä¸æ˜¯å­—æ¯æ•°å­—æˆ–@
    email_pattern = r'(?<![a-zA-Z0-9@])([a-zA-Z0-9_.+-]+)@([a-zA-Z0-9-]+\.[a-zA-Z0-9-.]+)(?![a-zA-Z0-9-.])'

    def email_replacer(match):
        username = match.group(1)
        domain = match.group(2)
        if len(username) > 2:
            return f'{username[:2]}***@{domain}'
        else:
            return f'{username}***@{domain}'

    text = re.sub(email_pattern, email_replacer, text)

    # 6. åœ°å€ - æœ€åå¤„ç†ï¼Œä½¿ç”¨æ›´çµæ´»çš„æ¨¡å¼
    city_list = ['åŒ—äº¬', 'ä¸Šæµ·', 'å¹¿å·', 'æ·±åœ³', 'æ­å·', 'æˆéƒ½', 'é‡åº†', 'æ­¦æ±‰', 'å—äº¬', 'å¤©æ´¥', 'è¥¿å®‰', 'é•¿æ²™', 'æ²ˆé˜³',
                 'éƒ‘å·', 'æµå—', 'é’å²›', 'è‹å·', 'æ— é”¡', 'å®æ³¢', 'ä¸œè']
    city_str = '|'.join(city_list)

    # æ”¹è¿›çš„åœ°å€æ¨¡å¼ï¼ŒåŒ¹é…åŸå¸‚+è¯¦ç»†åœ°å€ç›´åˆ°é‡åˆ°æ ‡ç‚¹æˆ–ç»“å°¾
    address_pattern = rf'(?P<city>{city_str})å¸‚?(?P<detail>[^ï¼Œã€‚ï¼ï¼Ÿï¼›,\.!?;]*?(?:è·¯|è¡—|å··|å·|å¼„|å°åŒº|å¹¢|å•å…ƒ|å®¤)[^ï¼Œã€‚ï¼ï¼Ÿï¼›,\.!?;]*)'

    def address_replacer(match):
        city = match.group('city')
        return f'{city}[åœ°å€è¯¦æƒ…å·²é®è”½]'

    text = re.sub(address_pattern, address_replacer, text)

    return text


@st.cache_data
def load_knowledge_base(uploaded_file):
    """
    åŠ è½½ç»Ÿä¸€çŸ¥è¯†åº“Excelæ–‡ä»¶,çŸ¥è¯†åº“åº”åŒ…å«`é—®é¢˜`ã€`é—®é¢˜ç±»å‹`ã€`æ ‡å‡†å›ç­”`ä¸‰åˆ—
    """
    try:
        df = pd.read_excel(uploaded_file)
        required_columns = ['é—®é¢˜', 'é—®é¢˜ç±»å‹', 'æ ‡å‡†å›ç­”']
        for col in required_columns:
            if col not in df.columns:
                st.error(f"çŸ¥è¯†åº“æ–‡ä»¶å¿…é¡»åŒ…å«'{col}'åˆ—")
                return None, None

        df = df.dropna(subset=['é—®é¢˜', 'æ ‡å‡†å›ç­”']).reset_index(drop=True)

        # æ‰©å±•åçš„è§„åˆ™åº“ - æ„å›¾è·¯ç”±å™¨ï¼Œå¼•å¯¼ç³»ç»Ÿå»çŸ¥è¯†åº“ä¸­æŸ¥æ‰¾ç­”æ¡ˆ
        rule_base = {
            # åŸæœ‰ç±»åˆ«
            "å‘ç¥¨å’¨è¯¢": {
                "patterns": ["å‘ç¥¨", "å¼€ç¥¨", "ä¸“ç¥¨", "æ™®ç¥¨", "ç¨ç‚¹", "å¼€å‘ç¥¨", "å¢å€¼ç¨", "æŠ¬å¤´", "å‘ç¥¨æŠ¬å¤´"],
            },
            "ç‰©æµæŸ¥è¯¢": {
                "patterns": ["å‘è´§", "å¿«é€’", "ç‰©æµ", "é¡ºä¸°", "é€è¾¾", "é…é€", "è¿è¾“", "å‡ å¤©åˆ°", "å‘è´§æ—¶é—´", "å¿«é€’å•å·",
                             "è¿è´¹", "å¿«é€’å…¬å¸"],
            },
            "é€€è´§æ”¿ç­–": {
                "patterns": ["é€€è´§", "é€€æ¬¾", "é€€æ¢è´§", "é€€è´§æµç¨‹", "é€€è´§æ”¿ç­–", "é€€è´§æ¡ä»¶", "é€€è´§è¿è´¹", "é€€è´§ç”³è¯·",
                             "é€€è´§æ€ä¹ˆé€€"],
            },
            "å”®åæ”¿ç­–": {
                "patterns": ["ä¿ä¿®", "è´¨ä¿", "ç»´ä¿®", "å”®å", "åäº†", "ä¿ä¿®æœŸ", "è´¨ä¿æœŸ", "ç»´ä¿®æœåŠ¡", "å”®åæ”¯æŒ",
                             "æŠ¥ä¿®"],
            },

            # æ–°å¢ç±»åˆ«
            "ä»·æ ¼å’¨è¯¢": {
                "patterns": ["ä»·æ ¼", "å¤šå°‘é’±", "ä»·", "ä¼˜æƒ ", "æŠ˜æ‰£", "ä¾¿å®œ", "ä»·ä½", "æŠ¥ä»·", "ä»·æ ¼å¤šå°‘", "æœ‰ä¼˜æƒ å—",
                             "ä»·æ ¼ä¼˜æƒ ", "æ‰“æŠ˜"],
            },
            "ç”µæœºæŠ€æœ¯å’¨è¯¢": {
                "patterns": ["ç”µæœº", "M0601", "M0602", "M1502", "M0603", "M0701", "M1505", "P1010",
                             "ç¼–ç å™¨", "å‡é€Ÿå™¨", "æ³¢ç‰¹ç‡", "CAN", "ä¸Šä½æœº", "ç”µå‹", "æ‰­çŸ©", "è½¬çŸ©",
                             "ç”µæµ", "è½¬é€Ÿ", "PID", "ä½ç½®ç¯", "é€Ÿåº¦ç¯", "ç”µæµç¯", "CANopen", "é€šä¿¡åè®®",
                             "ä¾‹ç¨‹", "ä»£ç ", "å›ºä»¶", "é©±åŠ¨ç¨‹åº", "å®‰è£…", "æ¥çº¿", "å‚æ•°", "è§„æ ¼", "å‚æ•°é…ç½®",
                             "ç”µæ± ", "ç”µæº", "ç”µå‹èŒƒå›´", "ä¾›ç”µ", "åŠŸç‡", "åŠ›çŸ©", "è´Ÿè½½", "æ‰¿é‡", "é‡é‡"],
            },
            "é€šç”¨é—®ç­”": {
                "patterns": ["ä½ å¥½", "æ‚¨å¥½", "hello", "hi", "æ—©ä¸Šå¥½", "ä¸‹åˆå¥½", "æ™šä¸Šå¥½", "åœ¨å—", "æœ‰äººå—", "å®¢æœ"],
            },
            "æ„Ÿè°¢ä¸å‘Šåˆ«": {
                "patterns": ["è°¢è°¢", "æ„Ÿè°¢", "è¾›è‹¦äº†", "å†è§", "æ‹œæ‹œ", "ä¸‹æ¬¡è§", "ç»“æŸäº†", "å¥½äº†", "æ²¡é—®é¢˜äº†"],
            }
        }

        return df, rule_base

    except Exception as e:
        st.error(f"çŸ¥è¯†åº“åŠ è½½å¤±è´¥: {str(e)}")
        return None, None


def find_in_knowledge_base(user_query, knowledge_df):
    """
    ç³»ç»Ÿæ ¸å¿ƒæŸ¥è¯¢å‡½æ•° - æ™ºèƒ½åŒ¹é…ç‰ˆï¼šå¹³è¡¡å‡†ç¡®æ€§å’Œå¬å›ç‡
    """
    print(f"\n=== DEBUG find_in_knowledge_base å¼€å§‹ ===")
    print(f"ç”¨æˆ·æŸ¥è¯¢: {user_query}")
    
    if knowledge_df is None or knowledge_df.empty:
        print(f"DEBUG: çŸ¥è¯†åº“ä¸ºç©º")
        return None, None
    
    # ====== ç¬¬ä¸€æ­¥ï¼šå¼ºåŠ›æ‹¦æˆªå¤–è§‚é—®é¢˜ ======
    # åªè¦åŒ…å«è¿™äº›å…³é”®è¯ï¼Œå°±è·³è¿‡çŸ¥è¯†åº“åŒ¹é…
    appearance_keywords = [
        "é¢œè‰²", "çº¢è‰²", "è“è‰²", "ç»¿è‰²", "é»„è‰²", "ç™½è‰²", "é»‘è‰²", "ç°è‰²", 
        "å¤–è§‚", "æ ·å­", "å¤–å½¢", "å½¢çŠ¶", "é•¿å¾—", 
        "å°ºå¯¸", "å¤§å°", "é•¿", "å®½", "é«˜", 
        "æè´¨", "ææ–™", "å¡‘æ–™", "é‡‘å±", 
        "é‡é‡", "é‡", "è½»", "å¤šé‡"
    ]
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«å¤–è§‚å…³é”®è¯
    for keyword in appearance_keywords:
        if keyword in user_query:
            print(f"DEBUG: å‘ç°å¤–è§‚å…³é”®è¯ '{keyword}'ï¼Œè·³è¿‡çŸ¥è¯†åº“åŒ¹é…")
            return None, None
    
    # ====== ç¬¬äºŒæ­¥ï¼šç²¾ç¡®åŒ¹é… ======
    exact_match = knowledge_df[knowledge_df['é—®é¢˜'].str.strip().str.lower() == user_query.strip().lower()]
    if not exact_match.empty:
        answer = exact_match.iloc[0]['æ ‡å‡†å›ç­”']
        print(f"DEBUG: ç²¾ç¡®åŒ¹é…æˆåŠŸï¼Œé—®é¢˜: {exact_match.iloc[0]['é—®é¢˜']}")
        return answer, exact_match.iloc[0].get('é—®é¢˜ç±»å‹', 'é€šç”¨å’¨è¯¢')
    
    print(f"DEBUG: ç²¾ç¡®åŒ¹é…å¤±è´¥")
    
    # ====== ç¬¬ä¸‰æ­¥ï¼šåˆå¹¶é—®é¢˜å¤„ç† ======
    # æ£€æŸ¥æ˜¯å¦æ˜¯åˆå¹¶é—®é¢˜ï¼ˆåŒ…å«"å’Œ"ã€"åŠ"ã€"è¿˜æœ‰"ç­‰è¿æ¥è¯ï¼‰
    connectors = ["å’Œ", "åŠ", "è¿˜æœ‰", "ä»¥åŠ", "å¹¶ä¸”", "åŒæ—¶", "ã€"]
    has_connector = any(connector in user_query for connector in connectors)
    
    if has_connector:
        print(f"DEBUG: æ£€æµ‹åˆ°åˆå¹¶é—®é¢˜ï¼Œå°è¯•æ‹†åˆ†å¤„ç†")
        
        # å°è¯•æ ¹æ®è¿æ¥è¯æ‹†åˆ†é—®é¢˜
        found_answers = []
        
        # æ£€æŸ¥å„ç§è¿æ¥è¯
        for connector in connectors:
            if connector in user_query:
                parts = [part.strip() for part in user_query.split(connector) if part.strip()]
                
                # å¦‚æœæ‹†åˆ†æˆè‡³å°‘2éƒ¨åˆ†ï¼Œå°è¯•åˆ†åˆ«åŒ¹é…
                if len(parts) >= 2:
                    print(f"DEBUG: æŒ‰'{connector}'æ‹†åˆ†ä¸º: {parts}")
                    
                    for part in parts:
                        # ä¸ºæ¯ä¸ªéƒ¨åˆ†æŸ¥æ‰¾æœ€ä½³åŒ¹é…
                        part_matches = []
                        
                        # 1. å­ä¸²åŒ¹é…
                        for idx, row in knowledge_df.iterrows():
                            question = row['é—®é¢˜'].strip().lower()
                            if part.lower() in question or question in part.lower():
                                part_matches.append((row['æ ‡å‡†å›ç­”'], row.get('é—®é¢˜ç±»å‹', 'é€šç”¨å’¨è¯¢'), 100))
                                break
                        
                        # 2. æ¨¡ç³ŠåŒ¹é…
                        if not part_matches:
                            result = process.extractOne(
                                part,
                                knowledge_df['é—®é¢˜'].tolist(),
                                scorer=fuzz.token_set_ratio
                            )
                            
                            if result:
                                best_match, score, index = result
                                if score >= 50:  # åˆå¹¶é—®é¢˜çš„éƒ¨åˆ†åŒ¹é…å¯ä»¥é™ä½é˜ˆå€¼
                                    matched_row = knowledge_df.iloc[index]
                                    part_matches.append((matched_row['æ ‡å‡†å›ç­”'], matched_row.get('é—®é¢˜ç±»å‹', 'é€šç”¨å’¨è¯¢'), score))
                        
                        if part_matches:
                            # é€‰æ‹©åˆ†æ•°æœ€é«˜çš„
                            part_matches.sort(key=lambda x: x[2], reverse=True)
                            found_answers.append(part_matches[0][0])
                            print(f"DEBUG: éƒ¨åˆ†'{part}'åŒ¹é…åˆ°ç­”æ¡ˆ")
        
        # å¦‚æœæœ‰æ‰¾åˆ°å¤šä¸ªç­”æ¡ˆï¼Œåˆå¹¶å®ƒä»¬
        if len(found_answers) >= 2:
            print(f"DEBUG: åˆå¹¶é—®é¢˜æ‰¾åˆ°{len(found_answers)}ä¸ªç­”æ¡ˆï¼Œè¿›è¡Œåˆå¹¶")
            
            # å»é‡
            unique_answers = []
            for ans in found_answers:
                if ans not in unique_answers:
                    unique_answers.append(ans)
            
            if len(unique_answers) == 1:
                return unique_answers[0], "ç»„åˆé—®é¢˜"
            else:
                # ç»„åˆå¤šä¸ªç­”æ¡ˆ
                combined_reply = "å…³äºæ‚¨çš„é—®é¢˜ï¼Œåˆ†åˆ«å›ç­”å¦‚ä¸‹ï¼š\n\n"
                for i, ans in enumerate(unique_answers, 1):
                    # æ¸…ç†ç­”æ¡ˆæ ¼å¼
                    clean_ans = ans.strip()
                    if not clean_ans.endswith(('ã€‚', '!', '?', 'ï¼', 'ï¼Ÿ')):
                        clean_ans += 'ã€‚'
                    combined_reply += f"{i}. {clean_ans}\n"
                
                return combined_reply, "ç»„åˆé—®é¢˜"
        elif found_answers:
            # åªæ‰¾åˆ°ä¸€ä¸ªç­”æ¡ˆï¼Œç›´æ¥è¿”å›
            return found_answers[0], "ç»„åˆé—®é¢˜"
    
    # ====== ç¬¬å››æ­¥ï¼šå­ä¸²åŒ¹é…ï¼ˆåŒå‘ï¼‰ ======
    # åªæœ‰å½“ç”¨æˆ·é—®é¢˜åœ¨çŸ¥è¯†åº“é—®é¢˜ä¸­æ˜¯å­ä¸²æ—¶æ‰åŒ¹é…ï¼Œæˆ–è€…åè¿‡æ¥
    for idx, row in knowledge_df.iterrows():
        question = row['é—®é¢˜'].strip().lower()
        user_q_lower = user_query.strip().lower()
        
        # åŒå‘å­ä¸²åŒ¹é…
        if user_q_lower in question or question in user_q_lower:
            print(f"DEBUG: å­ä¸²åŒ¹é…æˆåŠŸ: {user_query} -> {question}")
            return row['æ ‡å‡†å›ç­”'], row.get('é—®é¢˜ç±»å‹', 'é€šç”¨å’¨è¯¢')
    
    print(f"DEBUG: å­ä¸²åŒ¹é…å¤±è´¥")
    
    # ====== ç¬¬äº”æ­¥ï¼šæ™ºèƒ½æ¨¡ç³ŠåŒ¹é…ï¼ˆé’ˆå¯¹æŠ€æœ¯é—®é¢˜ï¼‰ ======
    # æ£€æŸ¥æ˜¯å¦æ˜¯æŠ€æœ¯é—®é¢˜
    technical_keywords = ["ç”µæœº", "M0601", "M0602", "M1502", "M0603", "M0701", "M1505", "P1010",
                         "ç¼–ç å™¨", "å‡é€Ÿå™¨", "æ³¢ç‰¹ç‡", "CAN", "ä¸Šä½æœº", "ç”µå‹", "æ‰­çŸ©", "è½¬çŸ©",
                         "ç”µæµ", "è½¬é€Ÿ", "PID", "ä½ç½®ç¯", "é€Ÿåº¦ç¯", "ç”µæµç¯", "CANopen", "é€šä¿¡åè®®",
                         "ä¾‹ç¨‹", "ä»£ç ", "å›ºä»¶", "é©±åŠ¨ç¨‹åº", "å®‰è£…", "æ¥çº¿", "å‚æ•°", "è§„æ ¼"]
    
    is_technical_question = any(keyword in user_query for keyword in technical_keywords)
    
    if is_technical_question:
        print(f"DEBUG: æ£€æµ‹åˆ°æŠ€æœ¯é—®é¢˜ï¼Œå°è¯•æ¨¡ç³ŠåŒ¹é…")
        
        # åªå¯¹æŠ€æœ¯é—®é¢˜è¿›è¡Œæ¨¡ç³ŠåŒ¹é…
        # rapidfuzz è¿”å›ä¸‰ä¸ªå€¼ï¼š(æœ€ä½³åŒ¹é…, åˆ†æ•°, ç´¢å¼•)
        result = process.extractOne(
            user_query,
            knowledge_df['é—®é¢˜'].tolist(),
            scorer=fuzz.token_set_ratio  # ä½¿ç”¨token_set_ratioï¼Œå¯¹è¯åºä¸æ•æ„Ÿ
        )
        
        if result:
            best_match, score, index = result
            print(f"DEBUG: æ¨¡ç³ŠåŒ¹é…ç»“æœ: {best_match}")
            print(f"DEBUG: åŒ¹é…åˆ†æ•°: {score}")
            print(f"DEBUG: åŒ¹é…ç´¢å¼•: {index}")
            
            # å¯¹äºæŠ€æœ¯é—®é¢˜ï¼Œé™ä½é˜ˆå€¼åˆ°50
            if score >= 50:  # é™ä½é˜ˆå€¼åˆ°50ï¼Œæé«˜å¬å›ç‡
                matched_row = knowledge_df.iloc[index]  # ç›´æ¥ä½¿ç”¨ç´¢å¼•è·å–è¡Œ
                
                # éªŒè¯åŒ¹é…çš„ç›¸å…³æ€§
                # æ£€æŸ¥åŒ¹é…åˆ°çš„é—®é¢˜æ˜¯å¦ä¹Ÿæ˜¯æŠ€æœ¯é—®é¢˜
                matched_is_technical = any(keyword in best_match for keyword in technical_keywords)
                
                if matched_is_technical:
                    print(f"DEBUG: æ¨¡ç³ŠåŒ¹é…æˆåŠŸï¼Œè¿”å›çŸ¥è¯†åº“ç­”æ¡ˆ")
                    return matched_row['æ ‡å‡†å›ç­”'], matched_row.get('é—®é¢˜ç±»å‹', 'é€šç”¨å’¨è¯¢')
                else:
                    print(f"DEBUG: åŒ¹é…åˆ°éæŠ€æœ¯é—®é¢˜ï¼Œæ‹’ç»è¿”å›")
            else:
                print(f"DEBUG: æ¨¡ç³ŠåŒ¹é…åˆ†æ•°ä¸è¶³ {score} < 50")
        else:
            print(f"DEBUG: æ¨¡ç³ŠåŒ¹é…æœªæ‰¾åˆ°ç»“æœ")
    
    # æ²¡æœ‰æ‰¾åˆ°åŒ¹é…
    print(f"DEBUG: æ‰€æœ‰åŒ¹é…æ–¹æ³•éƒ½å¤±è´¥")
    return None, None

def rule_engine(user_query, knowledge_df):
    """
    è¯†åˆ«æ„å›¾,å¹¶å°è¯•ä»å¯¹åº”ç±»å‹çš„çŸ¥è¯†åº“ä¸­è·å–ç­”æ¡ˆ
    """
    start_time = time.time()
    print(f"\n=== DEBUG rule_engine å¼€å§‹ ===")
    print(f"ç”¨æˆ·æŸ¥è¯¢: {user_query}")
    
    user_query_lower = user_query.lower()
    rule_base = st.session_state.rule_base
    
    # ==== æ–°å¢ï¼šç‰¹æ®Šå¤„ç†å¤–è§‚å±æ€§é—®é¢˜ ====
    # å®šä¹‰å¤–è§‚å±æ€§å…³é”®è¯ï¼ˆæ›´å…¨é¢ï¼‰
    appearance_keywords = [
        # é¢œè‰²ç›¸å…³
        "é¢œè‰²", "çº¢è‰²", "è“è‰²", "ç»¿è‰²", "é»„è‰²", "ç™½è‰²", "é»‘è‰²", "ç°è‰²", "é“¶è‰²", "é‡‘è‰²",
        "ä»€ä¹ˆé¢œè‰²", "é¢œè‰²æ˜¯", "å•¥é¢œè‰²", "é¢œè‰²çš„", "è‰²",
        # å¤–è§‚ç›¸å…³
        "å¤–è§‚", "æ ·å­", "å¤–å½¢", "å½¢çŠ¶", "é•¿å¾—", "é•¿ä»€ä¹ˆæ ·", "å¥½çœ‹", "æ¼‚äº®", "é¢œå€¼",
        "å¤–è§‚è®¾è®¡", "å¤–è§‚æ˜¯", "å¤–è§‚æ€ä¹ˆæ ·",
        # å°ºå¯¸ç›¸å…³
        "å°ºå¯¸", "å¤§å°", "é•¿", "å®½", "é«˜", "åšåº¦", "ç›´å¾„", "ä½“ç§¯", "å°ºå¯¸å¤šå¤§",
        "å¤šé•¿", "å¤šå®½", "å¤šé«˜", "å¤šå¤§å°ºå¯¸", "å¤§å°æ˜¯",
        # æè´¨ç›¸å…³
        "æè´¨", "ææ–™", "å¡‘æ–™", "é‡‘å±", "é“åˆé‡‘", "ä¸é”ˆé’¢", "é“", "é’¢",
        "ä»€ä¹ˆæè´¨", "ä»€ä¹ˆææ–™", "ç”¨çš„ä»€ä¹ˆ",
        # é‡é‡ç›¸å…³
        "é‡é‡", "é‡", "è½»", "å¤šé‡", "å‡ å…¬æ–¤", "å¤šå°‘å…‹", "é‡é‡å¤šå°‘"
    ]
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«å¤–è§‚å±æ€§å…³é”®è¯
    has_appearance_keyword = False
    matched_keywords = []
    for keyword in appearance_keywords:
        if keyword in user_query:
            has_appearance_keyword = True
            matched_keywords.append(keyword)
    
    print(f"æ˜¯å¦åŒ…å«å¤–è§‚å…³é”®è¯: {has_appearance_keyword}")
    if has_appearance_keyword:
        print(f"åŒ¹é…åˆ°çš„å¤–è§‚å…³é”®è¯: {matched_keywords}")
    
    # å…³é”®ä¿®æ”¹ï¼šåªè¦åŒ…å«å¤–è§‚å…³é”®è¯ï¼Œå°±å¼ºåˆ¶ä½¿ç”¨AIå¤„ç†
    if has_appearance_keyword:
        # ä½†éœ€è¦æ’é™¤æŠ€æœ¯ä¸Šä¸‹æ–‡ï¼ˆæ¯”å¦‚"çº¢è‰²æŒ‡ç¤ºç¯"ï¼‰
        technical_contexts = ["æŒ‡ç¤ºç¯", "LED", "ç¯", "æŠ¥è­¦", "æ•…éšœ", "çŠ¶æ€", "æ˜¾ç¤º", "ä¿¡å·", 
                             "ç”µå‹", "ç”µæµ", "è½¬é€Ÿ", "æ‰­çŸ©", "ç¼–ç å™¨", "å‡é€Ÿå™¨", "é€šä¿¡"]
        has_technical_context = any(context in user_query for context in technical_contexts)
        
        print(f"æ˜¯å¦åŒ…å«æŠ€æœ¯ä¸Šä¸‹æ–‡: {has_technical_context}")
        
        # å¦‚æœæ²¡æœ‰æŠ€æœ¯ä¸Šä¸‹æ–‡ï¼Œç›´æ¥å¼ºåˆ¶ä½¿ç”¨AI
        if not has_technical_context:
            end_time = time.time()
            print(f"DEBUG: å¤–è§‚é—®é¢˜ï¼Œå¼ºåˆ¶ä½¿ç”¨AIå¤„ç†")
            return {
                "source": "è§„åˆ™å¼•æ“",
                "intent": "å¤–è§‚å±æ€§å’¨è¯¢",
                "reply": None,  # è¿”å›Noneï¼Œè®©AIå¤„ç†
                "latency": end_time - start_time,
                "score": 0,
                "status": "failed"  # æ ‡è®°ä¸ºå¤±è´¥ï¼Œè®©åç»­æµç¨‹å¤„ç†
            }
    
    # ==== åŸæœ‰æ„å›¾è¯†åˆ«é€»è¾‘ ====
    detected_intent = None
    for intent, config in rule_base.items():
        if any(word in user_query_lower for word in config["patterns"]):
            detected_intent = intent
            print(f"è§„åˆ™å¼•æ“è¯†åˆ«åˆ°æ„å›¾: {intent}")
            break

    # ç‰¹æ®Šå¤„ç†ï¼šé€šç”¨é—®ç­”å’Œæ„Ÿè°¢å‘Šåˆ«
    if detected_intent == "é€šç”¨é—®ç­”":
        end_time = time.time()
        print(f"DEBUG: é€šç”¨é—®ç­”ï¼Œä½¿ç”¨é¢„è®¾å›å¤")
        return {
            "source": "ç³»ç»Ÿé¢„è®¾",
            "intent": "é€šç”¨é—®ç­”",
            "reply": "æ‚¨å¥½ï¼æˆ‘æ˜¯æœ¬æœ«ç§‘æŠ€çš„æ™ºèƒ½å®¢æœï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ã€‚æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ",
            "latency": end_time - start_time,
            "score": 100,
            "status": "success"
        }
    elif detected_intent == "æ„Ÿè°¢ä¸å‘Šåˆ«":
        end_time = time.time()
        print(f"DEBUG: æ„Ÿè°¢å‘Šåˆ«ï¼Œä½¿ç”¨é¢„è®¾å›å¤")
        return {
            "source": "ç³»ç»Ÿé¢„è®¾",
            "intent": "æ„Ÿè°¢ä¸å‘Šåˆ«",
            "reply": "ä¸å®¢æ°”ï¼Œè¿™æ˜¯æˆ‘åº”è¯¥åšçš„ï¼å¦‚æœ‰å…¶ä»–é—®é¢˜éšæ—¶è”ç³»æˆ‘ï¼Œç¥æ‚¨ç”Ÿæ´»æ„‰å¿«ï¼",
            "latency": end_time - start_time,
            "score": 100,
            "status": "success"
        }

    # æ— è®ºæ˜¯å¦è¯†åˆ«å‡ºå…·ä½“æ„å›¾ï¼Œéƒ½å…ˆåœ¨çŸ¥è¯†åº“ä¸­å…¨å±€æŸ¥æ‰¾
    print(f"è°ƒç”¨ find_in_knowledge_base...")
    reply, detected_type = find_in_knowledge_base(user_query, knowledge_df)

    end_time = time.time()

    if reply:
        # æˆåŠŸä»çŸ¥è¯†åº“ä¸­æ‰¾åˆ°ç­”æ¡ˆ
        # ä½¿ç”¨æ£€æµ‹åˆ°çš„é—®é¢˜ç±»å‹ä½œä¸ºæ„å›¾ï¼Œå¦‚æœæœªæŒ‡å®šåˆ™ä½¿ç”¨è§„åˆ™å¼•æ“æ£€æµ‹çš„æ„å›¾
        intent_used = detected_type if detected_type else (detected_intent if detected_intent else "çŸ¥è¯†åº“åŒ¹é…")
        print(f"DEBUG: çŸ¥è¯†åº“åŒ¹é…æˆåŠŸï¼Œè¿”å›ç­”æ¡ˆ")
        print(f"åŒ¹é…åˆ°çš„é—®é¢˜ç±»å‹: {detected_type}")
        print(f"ä½¿ç”¨çš„æ„å›¾: {intent_used}")
        return {
            "source": f"çŸ¥è¯†åº“ ({intent_used})",
            "intent": intent_used,
            "reply": reply,
            "latency": end_time - start_time,
            "score": 100,
            "status": "success"
        }
    else:
        # çŸ¥è¯†åº“ä¸­æœªæ‰¾åˆ°ç­”æ¡ˆ
        print(f"DEBUG: çŸ¥è¯†åº“æœªæ‰¾åˆ°ç­”æ¡ˆ")
        return {
            "source": "è§„åˆ™å¼•æ“",
            "intent": detected_intent if detected_intent else "æœªè¯†åˆ«",
            "reply": None,
            "latency": end_time - start_time,
            "score": 0,
            "status": "failed"
        }

def ai_enhancement_with_knowledge(user_query, history_window, knowledge_df):
    """
    å¢å¼ºç‰ˆAIç”Ÿæˆå›å¤ï¼šç»“åˆçŸ¥è¯†åº“ä¸­çš„ç›¸å…³ä¿¡æ¯ï¼Œç”Ÿæˆç®€æ´å›ç­”
    """
    start_time = time.time()
    
    # 1. æ£€æŸ¥æ˜¯å¦æ˜¯å¤–è§‚å±æ€§é—®é¢˜
    is_appearance_question = False
    appearance_keywords = [
        "é¢œè‰²", "çº¢è‰²", "è“è‰²", "ç»¿è‰²", "é»„è‰²", "ç™½è‰²", "é»‘è‰²", "å¤–è§‚", "æ ·å­", 
        "å¤–å½¢", "å½¢çŠ¶", "é•¿å¾—", "å°ºå¯¸", "å¤§å°", "é•¿", "å®½", "é«˜", "æè´¨", "ææ–™",
        "é‡é‡", "å¤šé‡", "é‡"
    ]
    
    if any(keyword in user_query for keyword in appearance_keywords):
        is_appearance_question = True
    
    # 2. ä»çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³ä¸Šä¸‹æ–‡
    relevant_knowledge = ""
    if knowledge_df is not None and not knowledge_df.empty:
        # å°è¯•æŸ¥æ‰¾æœ€ç›¸å…³çš„é—®é¢˜
        best_answer, _ = find_in_knowledge_base(user_query, knowledge_df)
        if best_answer:
            relevant_knowledge = f"çŸ¥è¯†åº“æ ‡å‡†ç­”æ¡ˆï¼š{best_answer}\n\n"
    
    # 3. æ„å»ºPrompt - ç‰¹åˆ«è¦æ±‚ç®€æ´å›ç­”
    history_text = "\n".join([f"ç”¨æˆ·ï¼š{q}\nå®¢æœ:{a}" for q, a in history_window])
    
    # æ ¹æ®é—®é¢˜ç±»å‹è°ƒæ•´Prompt
    technical_keywords = ["ç”µæœº", "M0601", "M0602", "M1502", "ç¼–ç å™¨", "å‡é€Ÿå™¨", "CAN", 
                         "ä¸Šä½æœº", "ç”µå‹", "ä»£ç ", "ä¾‹ç¨‹", "é€šä¿¡", "æ³¢ç‰¹ç‡"]
    
    is_technical = any(keyword in user_query for keyword in technical_keywords)
    
    if is_technical and relevant_knowledge:
        # æŠ€æœ¯é—®é¢˜ä¸”æœ‰çŸ¥è¯†åº“ç­”æ¡ˆæ—¶ï¼Œç”Ÿæˆç®€æ´å›ç­”
        full_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æœºå™¨äººäº§å“æ·˜å®å®¢æœAIåŠ©æ‰‹ã€‚

**é‡è¦æŒ‡ä»¤**ï¼š
1. ä¸‹é¢æä¾›äº†çŸ¥è¯†åº“ä¸­çš„æ ‡å‡†ç­”æ¡ˆ
2. å¦‚æœçŸ¥é“ç¡®åˆ‡ç­”æ¡ˆï¼Œè¯·å‡†ç¡®ã€ç®€æ´åœ°å›ç­”
3. å¦‚æœä¸çŸ¥é“ç¡®åˆ‡ç­”æ¡ˆï¼Œè¯·è¯´"æŠ±æ­‰ï¼Œæˆ‘æš‚æ—¶æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜ï¼Œå»ºè®®æ‚¨è”ç³»å®¢æœæˆ–æŸ¥çœ‹äº§å“è¯´æ˜ä¹¦"
4. ç»å¯¹ä¸è¦ç¼–é€ å‚æ•°ã€è§„æ ¼ã€å…¬å¸åœ°å€ç­‰å…·ä½“ä¿¡æ¯ï¼Œå°¤å…¶æ˜¯çŸ¥è¯†åº“æ²¡æœ‰æåˆ°çš„ä¿¡æ¯ã€‚ä¸è¦çŒœæµ‹
5. å¦‚æœç”¨æˆ·é—®çš„æ˜¯æŠ€æœ¯å‚æ•°ï¼Œç›´æ¥å›ç­”å‚æ•°

**çŸ¥è¯†åº“æ ‡å‡†ç­”æ¡ˆ**ï¼š
{relevant_knowledge}

**å½“å‰ç”¨æˆ·é—®é¢˜**ï¼š
{user_query}

è¯·ç”Ÿæˆç®€æ´ã€ä¸“ä¸šçš„å®¢æœå›å¤ï¼ˆæœ€å¥½åœ¨50å­—ä»¥å†…ï¼‰ï¼š"""
    elif is_appearance_question:
        # å¤–è§‚é—®é¢˜
        full_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æœºå™¨äººäº§å“æ·˜å®å®¢æœAIåŠ©æ‰‹ã€‚

ç”¨æˆ·é—®äº†ä¸€ä¸ªå…³äºäº§å“å¤–è§‚/é¢œè‰²/å°ºå¯¸çš„é—®é¢˜ï¼Œä½†çŸ¥è¯†åº“ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ã€‚

**å½“å‰ç”¨æˆ·é—®é¢˜**ï¼š
{user_query}

è¯·æ ¹æ®å¸¸è¯†ç”Ÿæˆç®€çŸ­å›å¤ï¼ˆ30å­—ä»¥å†…ï¼‰ï¼Œå¦‚æœä¸çŸ¥é“ç¡®åˆ‡ä¿¡æ¯ï¼Œå¯ä»¥è¯´æ˜æƒ…å†µå¹¶æä¾›å¸®åŠ©æ–¹å¼ã€‚"""
    else:
        # å…¶ä»–é—®é¢˜
        full_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æœºå™¨äººäº§å“æ·˜å®å®¢æœAIåŠ©æ‰‹ã€‚

**é‡è¦æŒ‡ä»¤**ï¼š
1. è¯·ä¼˜å…ˆå‚è€ƒä¸‹é¢çš„çŸ¥è¯†åº“ä¿¡æ¯
2. å¦‚æœçŸ¥è¯†åº“ä¿¡æ¯èƒ½å›ç­”ç”¨æˆ·é—®é¢˜ï¼Œè¯·åŸºäºçŸ¥è¯†åº“ä¿¡æ¯ç”Ÿæˆç®€æ´å›å¤
3. å¦‚æœçŸ¥è¯†åº“ä¿¡æ¯ä¸å®Œæ•´ï¼Œå¯ä»¥è¡¥å……ä½ çš„ä¸“ä¸šçŸ¥è¯†ã€‚
4. ä½†æ˜¯æ¶‰åŠåˆ°ä½ ä¸ç¡®å®šä¸”çŸ¥è¯†åº“å®Œå…¨æ²¡å‡ºç°çš„å†…å®¹æ—¶ï¼Œè¯·è¯´æŠ±æ­‰æˆ‘ä¸çŸ¥é“ï¼Œå»ºè®®æ‚¨è”ç³»å®¢æœæˆ–æŸ¥çœ‹å…¬å¸å®˜ç½‘æˆ–äº§å“è¯´æ˜ä¹¦ã€‚
5. æ³¨æ„ä¸è¦æ³„éœ²ä»»ä½•éšç§ä¿¡æ¯
6. ä¿æŒå›ç­”ç®€æ´æ˜äº†

**çŸ¥è¯†åº“å‚è€ƒä¿¡æ¯**ï¼š
{relevant_knowledge if relevant_knowledge else "ï¼ˆæš‚æ— ç›¸å…³å‚è€ƒä¿¡æ¯ï¼‰"}

**å¯¹è¯å†å²(æœ€è¿‘3è½®)**ï¼š
{history_text if history_text else "ï¼ˆæš‚æ— å†å²å¯¹è¯ï¼‰"}

**å½“å‰ç”¨æˆ·é—®é¢˜**ï¼š
{user_query}

è¯·ç”Ÿæˆç®€æ´ã€å‹å¥½çš„å®¢æœå›å¤ï¼š"""

    try:
        # è·å–APIå¯†é’¥
        api_key = st.session_state.get('api_key', '')
        if not api_key:
            api_key = os.getenv('DASHSCOPE_API_KEY', '')
            if not api_key:
                return {
                    "source": "AIæ¨¡å‹",
                    "intent": "æœªè¯†åˆ«",
                    "reply": "âš ï¸ æœªé…ç½®APIå¯†é’¥ï¼Œè¯·åœ¨ä¾§è¾¹æ è®¾ç½®",
                    "latency": time.time() - start_time,
                    "status": "failed"
                }
        
        response = Generation.call(
            model="qwen-plus",
            prompt=full_prompt,
            temperature=0.3,
            api_key=api_key
        )
        
        end_time = time.time()
        
        if response.status_code == 200:
            reply = response.output.text
            reply = desensitize(reply)
                        
            return {
                "source": "AIæ¨¡å‹" + ("ï¼ˆå¤–è§‚å’¨è¯¢ï¼‰" if is_appearance_question else "ï¼ˆå¢å¼ºç‰ˆï¼‰"),
                "intent": "å¤–è§‚å±æ€§å’¨è¯¢" if is_appearance_question else "æœªè¯†åˆ«",
                "reply": reply,
                "latency": end_time - start_time,
                "status": "success"
            }
        else:
            return {
                "source": "AIæ¨¡å‹",
                "intent": "æœªè¯†åˆ«",
                "reply": f"è¯·æ±‚å¤±è´¥ï¼Œè¯·ç¨åå†è¯• (é”™è¯¯ç : {response.status_code})",
                "latency": end_time - start_time,
                "status": "failed"
            }
    except Exception as e:
        end_time = time.time()
        return {
            "source": "AIæ¨¡å‹",
            "intent": "æœªè¯†åˆ«",
            "reply": f"APIè°ƒç”¨å¼‚å¸¸: {str(e)[:50]}...",
            "latency": end_time - start_time,
            "status": "failed"
        }

def process_query(user_query):
    """
    çŸ¥è¯†åº“ä¼˜å…ˆ,åŒ¹é…å¤±è´¥æ—¶è°ƒç”¨å¢å¼ºç‰ˆAIæ¨¡å‹ï¼ˆå¸¦çŸ¥è¯†åº“ä¸Šä¸‹æ–‡ï¼‰
    """
    print(f"\n=== DEBUG process_query å¼€å§‹ ===")
    print(f"ç”¨æˆ·æŸ¥è¯¢: {user_query}")
    
    knowledge_df = st.session_state.knowledge_df
    
    # ç›´æ¥ä½¿ç”¨è§„åˆ™å¼•æ“
    rule_result = rule_engine(user_query, knowledge_df)
    
    print(f"DEBUG: rule_engine è¿”å›çŠ¶æ€: {rule_result['status']}")
    print(f"DEBUG: rule_engine è¿”å›source: {rule_result['source']}")
    
    if rule_result["status"] == "success":
        print(f"DEBUG: ä½¿ç”¨çŸ¥è¯†åº“/é¢„è®¾å›å¤")
        # è®°å½•åˆ°å¯¹è¯å†å²
        st.session_state.history.appendleft((user_query, rule_result["reply"]))
        st.session_state.all_conversations.append({
            "query": user_query,
            "reply": rule_result["reply"],
            "source": rule_result["source"],
            "time": time.strftime("%H:%M:%S"),
            "latency": rule_result["latency"]
        })
        return rule_result
    else:
        print(f"DEBUG: è°ƒç”¨AIå¢å¼ºç‰ˆ")
        # çŸ¥è¯†åº“æ— æ³•å›ç­”ï¼Œè°ƒç”¨å¢å¼ºç‰ˆAI
        ai_result = ai_enhancement_with_knowledge(
            user_query, 
            st.session_state.history,
            knowledge_df
        )
        
        # è®°å½•åˆ°å¯¹è¯å†å²
        st.session_state.history.appendleft((user_query, ai_result["reply"]))
        st.session_state.all_conversations.append({
            "query": user_query,
            "reply": ai_result["reply"],
            "source": ai_result["source"],
            "time": time.strftime("%H:%M:%S"),
            "latency": ai_result["latency"]
        })
        return ai_result


def generate_statistics_chart():
    """ç”Ÿæˆç®€å•çš„ç»Ÿè®¡å›¾è¡¨"""
    if len(st.session_state.all_conversations) == 0:
        return None

    df = pd.DataFrame(st.session_state.all_conversations)

    # åˆ›å»ºå›¾è¡¨
    fig, axes = plt.subplots(1, 2, figsize=(12, 4))

    # è§¦å‘æ¥æºåˆ†å¸ƒ
    source_counts = df['source'].value_counts()
    axes[0].pie(source_counts.values, labels=source_counts.index, autopct='%1.1f%%', startangle=90)
    axes[0].set_title('è§¦å‘æ¥æºåˆ†å¸ƒ')

    # å“åº”æ—¶é—´è¶‹åŠ¿
    if len(df) > 1:
        df['index'] = range(len(df))
        axes[1].plot(df['index'], df['latency'], marker='o')
        axes[1].set_xlabel('å¯¹è¯åºå·')
        axes[1].set_ylabel('å“åº”æ—¶é—´(ç§’)')
        axes[1].set_title('å“åº”æ—¶é—´è¶‹åŠ¿')
        axes[1].grid(True, alpha=0.3)

    plt.tight_layout()
    return fig


# Streamlitç•Œé¢
def main():
    st.title("ğŸ¤– æœºå™¨äººå®¢æœAIåŠ©æ‰‹æ¼”ç¤ºç³»ç»Ÿ")
    st.markdown("---")

    # ä¾§è¾¹æ  - é…ç½®åŒºåŸŸ
    with st.sidebar:
        st.header("âš™ï¸ ç³»ç»Ÿé…ç½®")

        # APIå¯†é’¥è®¾ç½®
        with st.expander("APIé…ç½®"):
            # è·å–å½“å‰session_stateä¸­çš„APIå¯†é’¥ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™æ˜¾ç¤ºç©ºå­—ç¬¦ä¸²
            current_api_key = st.session_state.get('api_key', '')
            api_key = st.text_input("é€šä¹‰åƒé—®APIå¯†é’¥",
                                    type="password",
                                    value=current_api_key,
                                    help="è¾“å…¥ä½ çš„é˜¿é‡Œäº‘DashScope APIå¯†é’¥")

            # å½“ç”¨æˆ·è¾“å…¥APIå¯†é’¥åï¼Œä¿å­˜åˆ°session_state
            if api_key and api_key != current_api_key:
                st.session_state['api_key'] = api_key
                st.success("APIå¯†é’¥å·²æ›´æ–°!")

            # æ·»åŠ ä¸€ä¸ªæµ‹è¯•è¿æ¥æŒ‰é’®
            if st.button("æµ‹è¯•APIè¿æ¥"):
                if st.session_state.get('api_key'):
                    dashscope.api_key = st.session_state['api_key']
                    try:
                        # ç®€å•æµ‹è¯•è°ƒç”¨
                        test_response = Generation.call(
                            model="qwen-plus",
                            prompt="ä½ å¥½",
                            temperature=0.1
                        )
                        if test_response.status_code == 200:
                            st.success("APIè¿æ¥æˆåŠŸ!")
                        else:
                            st.error(f"APIè¿æ¥å¤±è´¥: {test_response.message}")
                    except Exception as e:
                        st.error(f"è¿æ¥å¼‚å¸¸: {str(e)}")
                else:
                    st.warning("è¯·å…ˆè¾“å…¥APIå¯†é’¥")

        # æ•°æ®ä¸Šä¼ 
        st.subheader("ğŸ“Š æ•°æ®ä¸Šä¼ ")
        uploaded_file = st.file_uploader("ä¸Šä¼ çŸ¥è¯†åº“Excelæ–‡ä»¶", type=['xlsx'],
                                         help="è¯·ç¡®ä¿æ–‡ä»¶åŒ…å«'é—®é¢˜'ã€'é—®é¢˜ç±»å‹'ã€'æ ‡å‡†å›ç­”'ä¸‰åˆ—")

        if uploaded_file is not None:
            if st.button("åŠ è½½çŸ¥è¯†åº“"):
                with st.spinner("æ­£åœ¨åŠ è½½çŸ¥è¯†åº“..."):
                    # è°ƒç”¨æ›´æ–°åçš„åŠ è½½å‡½æ•°ï¼Œç°åœ¨è¿”å›ä¸¤ä¸ªå€¼
                    df, rule_base = load_knowledge_base(uploaded_file)
                    if df is not None:
                        # æ›´æ–°Session Stateå˜é‡å
                        st.session_state.knowledge_df = df
                        st.session_state.rule_base = rule_base
                        st.success(f"âœ… æˆåŠŸåŠ è½½ {len(df)} æ¡çŸ¥è¯†è®°å½•")

                        # æ˜¾ç¤ºé—®é¢˜ç±»å‹åˆ†å¸ƒï¼Œä½“ç°æ–°æ¶æ„ä¼˜åŠ¿
                        if 'é—®é¢˜ç±»å‹' in df.columns:
                            type_counts = df['é—®é¢˜ç±»å‹'].value_counts()
                            type_info = ", ".join([f"{k}({v}æ¡)" for k, v in type_counts.items()])
                            st.info(f"**é—®é¢˜ç±»å‹åˆ†å¸ƒ:** {type_info}")

                            # æ˜¾ç¤ºè§„åˆ™åº“è¦†ç›–æƒ…å†µ
                            rule_categories = list(rule_base.keys())
                            st.info(f"**è§„åˆ™åº“è¦†ç›–:** {len(rule_categories)}ä¸ªæ„å›¾ç±»åˆ«")

        # ç³»ç»ŸçŠ¶æ€ - æ›´æ–°å˜é‡å
        st.subheader("ğŸ“ˆ ç³»ç»ŸçŠ¶æ€")
        st.metric("å¯¹è¯æ€»æ•°", len(st.session_state.all_conversations))
        st.metric("å†å²çª—å£å¤§å°", len(st.session_state.history))
        if st.session_state.knowledge_df is not None:
            st.metric("çŸ¥è¯†åº“æ¡ç›®", len(st.session_state.knowledge_df))
        if st.session_state.rule_base is not None:
            st.metric("è§„åˆ™åº“ç±»åˆ«", len(st.session_state.rule_base))

        # æ¸…ç©ºå¯¹è¯æŒ‰é’®
        if st.button("æ¸…ç©ºå¯¹è¯å†å²"):
            st.session_state.history.clear()
            st.session_state.all_conversations.clear()
            st.success("å¯¹è¯å†å²å·²æ¸…ç©º")

    # ä¸»ç•Œé¢ - ä¸¤åˆ—å¸ƒå±€
    col1, col2 = st.columns([2, 1])

    with col1:
        st.subheader("ğŸ’¬ å®¢æœå·¥ä½œå°")

        # åˆå§‹åŒ– session_state
        if 'user_query' not in st.session_state:
            st.session_state.user_query = ""
        if 'query_submitted' not in st.session_state:
            st.session_state.query_submitted = False

        # ç¤ºä¾‹é—®é¢˜åˆ—è¡¨ - æŒ‰ç±»åˆ«åˆ†ç»„
        examples_by_category = {
            "ç”µæœºæŠ€æœ¯å’¨è¯¢": [
                "M0601Cç”µæœºå¸¦å‡é€Ÿå™¨å—?",
                "M0603Cç”µæœºæ”¯æŒCANé€šä¿¡å—?",
                "ç”µæœºå¯ä»¥ç”¨24Vç”µå‹å—?",
                "æœ‰ä»£ç ä¾‹ç¨‹å’Œä¸Šä½æœºå—?"
            ],
            "ç‰©æµæŸ¥è¯¢": [
                "ä»€ä¹ˆæ—¶å€™å‘è´§ï¼Ÿ",
                "å¿«é€’å‡ å¤©èƒ½åˆ°?",
                "å‘ä»€ä¹ˆå¿«é€’ï¼Ÿ",
                "è¿è´¹æ€ä¹ˆç®—ï¼Ÿ"
            ],
            "å‘ç¥¨å’¨è¯¢": [
                "å¯ä»¥å¼€å‘ç¥¨å—ï¼Ÿ",
                "å¯ä»¥å¼€ä¸“ç¥¨å—ï¼Ÿ",
                "å‘ç¥¨æ€ä¹ˆå¼€ï¼Ÿ",
                "å‘ç¥¨å¼€é”™äº†å¯ä»¥é‡å¼€å—ï¼Ÿ"
            ],
            "ä»·æ ¼ä¸å”®å": [
                "äº§å“æœ‰ä¼˜æƒ å—ï¼Ÿèƒ½ä¾¿å®œç‚¹å—?",
                "æ€ä¹ˆç”³è¯·é€€è´§ï¼Ÿ",
                "ä¿ä¿®æœŸå¤šä¹…?",
                "è¿è´¹å¯ä»¥ä¾¿å®œå—ï¼Ÿ"
            ]
        }

        # æ˜¾ç¤ºç¤ºä¾‹é—®é¢˜
        st.markdown("**å¿«é€Ÿæé—®ï¼ˆç‚¹å‡»ç›´æ¥ä½¿ç”¨ï¼‰**")

        # åˆ›å»ºä¸€ä¸ªå®¹å™¨æ¥æ˜¾ç¤ºç¤ºä¾‹æŒ‰é’®
        example_container = st.container()

        # ä½¿ç”¨tabæ˜¾ç¤ºä¸åŒç±»åˆ«
        tabs = example_container.tabs(list(examples_by_category.keys()))

        for tab_idx, (category, examples) in enumerate(examples_by_category.items()):
            with tabs[tab_idx]:
                cols = st.columns(2)
                for idx, example in enumerate(examples):
                    col_idx = idx % 2
                    with cols[col_idx]:
                        # å®šä¹‰æŒ‰é’®ç‚¹å‡»å›è°ƒå‡½æ•°
                        def set_example_query(example=example):
                            st.session_state.user_query = example
                            st.session_state.query_submitted = True

                        btn_text = f"ğŸ“Œ {example[:20]}..." if len(example) > 20 else f"ğŸ“Œ {example}"
                        st.button(
                            btn_text,
                            key=f"ex_btn_{category}_{idx}",
                            on_click=set_example_query,
                            use_container_width=True
                        )

        st.markdown("---")

        # ä½¿ç”¨ form æ¥ç®¡ç†è¾“å…¥å’Œæäº¤
        with st.form(key="query_form", clear_on_submit=False):
            # æ˜¾ç¤ºå½“å‰å·²é€‰ä¸­çš„é—®é¢˜
            current_query = st.session_state.user_query
            query_display = st.text_input(
                "å·²é€‰é—®é¢˜:",
                value=current_query,
                disabled=True,
                key="query_display"
            )

            # å…è®¸ç”¨æˆ·ç¼–è¾‘
            user_query = st.text_area(
                "ç¼–è¾‘æˆ–è¾“å…¥æ–°é—®é¢˜ï¼š",
                value=current_query,
                placeholder="ä¾‹å¦‚:M0601Cç”µæœºå¸¦å‡é€Ÿå™¨å—?ç¼–ç å™¨æ˜¯ç»å¯¹å¼çš„å—?",
                height=100,
                key="user_input"
            )

            # æäº¤æŒ‰é’®
            submit_col1, submit_col2 = st.columns([2, 1])
            with submit_col1:
                submitted = st.form_submit_button("ğŸš€ è·å–AIå›å¤", type="primary", use_container_width=True)
            with submit_col2:
                clear_clicked = st.form_submit_button("ğŸ—‘ï¸ æ¸…ç©º", type="secondary", use_container_width=True)

            # å½“æ¸…ç©ºæŒ‰é’®è¢«ç‚¹å‡»æ—¶
            if clear_clicked:
                st.session_state.user_query = ""
                # è¿™é‡Œä¸éœ€è¦ rerunï¼Œå› ä¸ºæ¸…ç©ºåï¼Œè¡¨å•é‡æ–°æ¸²æŸ“æ—¶ä¼šä½¿ç”¨ç©ºå€¼

            # å½“è¡¨å•æäº¤æ—¶
            if submitted and user_query:
                # æ›´æ–° session_state
                st.session_state.user_query = user_query
                st.session_state.query_submitted = True

        # å½“ query_submitted ä¸º True æ—¶ï¼Œå¤„ç†æŸ¥è¯¢
        if st.session_state.query_submitted and st.session_state.user_query:
            # é‡ç½®æäº¤çŠ¶æ€
            st.session_state.query_submitted = False

            if st.session_state.knowledge_df is None:
                st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ çŸ¥è¯†åº“æ•°æ®")
            else:
                with st.spinner("æ­£åœ¨ç”Ÿæˆå›å¤..."):
                    result = process_query(st.session_state.user_query)

                    # æ˜¾ç¤ºç»“æœ
                    st.markdown("---")
                    
                    # ============ é”™è¯¯å¤„ç†éƒ¨åˆ† ============
                    if result["status"] == "failed":
                        st.error(f"âš ï¸ ç³»ç»Ÿå¤„ç†é‡åˆ°é—®é¢˜: {result['reply']}")
                        
                        # æä¾›å¤‡é€‰æ–¹æ¡ˆ
                        st.markdown("### ğŸ” å»ºè®®å°è¯•ä»¥ä¸‹æ–¹æ³•:")
                        st.markdown("1. å°†å¤æ‚é—®é¢˜æ‹†åˆ†ä¸ºå¤šä¸ªç®€å•é—®é¢˜è¯¢é—®")
                        st.markdown("2. æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æ­£ç¡®é…ç½®")
                        st.markdown("3. ç¨åé‡è¯•æˆ–è”ç³»æŠ€æœ¯æ”¯æŒ")
                        
                        # å¦‚æœçŸ¥è¯†åº“æœ‰ç›¸å…³å†…å®¹ï¼Œå°è¯•æä¾›ä¸€äº›å¯èƒ½çš„ç­”æ¡ˆ
                        if st.session_state.knowledge_df is not None:
                            # å°è¯•ä»çŸ¥è¯†åº“ä¸­æ‰¾åˆ°éƒ¨åˆ†ç›¸å…³ç­”æ¡ˆ
                            query_lower = st.session_state.user_query.lower()
                            related_questions = []
                            
                            # æ£€æŸ¥å¸¸è§å…³é”®è¯
                            keywords = ["ä»£ç ", "ä¾‹ç¨‹", "ä¸Šä½æœº", "ç”µæœº", "æ§åˆ¶", "è½¯ä»¶"]
                            for keyword in keywords:
                                if keyword in query_lower:
                                    matches = st.session_state.knowledge_df[
                                        st.session_state.knowledge_df['é—®é¢˜'].str.contains(keyword, case=False, na=False)
                                    ]
                                    if not matches.empty:
                                        for _, row in matches.head(2).iterrows():
                                            related_questions.append({
                                                "é—®é¢˜": row['é—®é¢˜'],
                                                "ç­”æ¡ˆ": row['æ ‡å‡†å›ç­”']
                                            })
                            
                            if related_questions:
                                st.markdown("### ğŸ“š çŸ¥è¯†åº“ç›¸å…³é—®ç­”:")
                                for i, item in enumerate(related_questions[:3], 1):
                                    with st.expander(f"ç›¸å…³é—®ç­” {i}: {item['é—®é¢˜'][:30]}..."):
                                        st.markdown(f"**é—®é¢˜:** {item['é—®é¢˜']}")
                                        st.markdown(f"**ç­”æ¡ˆ:** {item['ç­”æ¡ˆ']}")
                        
                        # ç»“æŸå½“å‰å¤„ç†
                        st.stop()

                    # ============ æ­£å¸¸ç»“æœæ˜¾ç¤º ============
                    with st.container():
                        st.markdown("### ğŸ¤– AIå›å¤å»ºè®®")

                        # æ˜¾ç¤ºæ¥æºæ ‡ç­¾
                        source_text = result["source"]
                        if "çŸ¥è¯†åº“" in source_text:
                            source_color = "#4CAF50"  # ç»¿è‰²
                            icon = "ğŸ“š"
                        elif "AIæ¨¡å‹" in source_text:
                            source_color = "#2196F3"  # è“è‰²
                            icon = "ğŸ¤–"
                        elif "ç³»ç»Ÿé¢„è®¾" in source_text:
                            source_color = "#9C27B0"  # ç´«è‰²
                            icon = "âš™ï¸"
                        else:
                            source_color = "#FF9800"  # æ©™è‰²
                            icon = "ğŸ”§"

                        # æ˜¾ç¤ºæ„å›¾æ ‡ç­¾
                        intent_text = result.get("intent", "æœªè¯†åˆ«")
                        intent_colors = {
                            "å‘ç¥¨å’¨è¯¢": "#FF5722",
                            "ç‰©æµæŸ¥è¯¢": "#3F51B5",
                            "é€€è´§æ”¿ç­–": "#E91E63",
                            "å”®åæ”¿ç­–": "#009688",
                            "ä»·æ ¼å’¨è¯¢": "#FF9800",
                            "ç”µæœºæŠ€æœ¯å’¨è¯¢": "#795548",
                            "é€šç”¨é—®ç­”": "#9C27B0",
                            "æ„Ÿè°¢ä¸å‘Šåˆ«": "#607D8B",
                            "æœªè¯†åˆ«": "#9E9E9E"
                        }
                        intent_color = intent_colors.get(intent_text, "#9E9E9E")

                        col_source, col_intent, col_time = st.columns([2, 2, 1])
                        with col_source:
                            st.markdown(f"""
                            <div style="background-color:{source_color}; color:white; padding:5px 10px; 
                                        border-radius:5px; display:inline-block; margin-bottom:10px;">
                                {icon} {source_text}
                            </div>
                            """, unsafe_allow_html=True)
                        with col_intent:
                            st.markdown(f"""
                            <div style="background-color:{intent_color}; color:white; padding:5px 10px; 
                                        border-radius:5px; display:inline-block; margin-bottom:10px;">
                                ğŸ·ï¸ {intent_text}
                            </div>
                            """, unsafe_allow_html=True)
                        with col_time:
                            st.markdown(f"""
                            <div style="background-color:#616161; color:white; padding:5px 10px; 
                                        border-radius:5px; display:inline-block; margin-bottom:10px;">
                                â±ï¸ {result["latency"]:.2f}ç§’
                            </div>
                            """, unsafe_allow_html=True)

                        # æ˜¾ç¤ºå›å¤å†…å®¹
                        st.markdown(f"""
                        <div style="background-color:#f5f5f5; padding:15px; border-radius:5px; 
                                    border-left:4px solid {source_color}; margin:10px 0;">
                            {result["reply"]}
                        </div>
                        """, unsafe_allow_html=True)

                        # ä¸€é”®å¤åˆ¶æŒ‰é’®
                        st.code(result["reply"], language=None)

                        # æç¤ºä¿¡æ¯
                        if "çŸ¥è¯†åº“" in source_text:
                            st.caption("âœ… æ­¤å›å¤æ¥è‡ªçŸ¥è¯†åº“æ ‡å‡†ç­”æ¡ˆï¼Œå‡†ç¡®å¯é ")
                        elif "AIæ¨¡å‹" in source_text:
                            st.caption("ğŸ¤– æ­¤å›å¤ç”±AIç”Ÿæˆï¼Œè¯·ä»”ç»†æ ¸å¯¹")
                        elif "ç³»ç»Ÿé¢„è®¾" in source_text:
                            st.caption("âš™ï¸ æ­¤å›å¤æ¥è‡ªç³»ç»Ÿé¢„è®¾æ¨¡æ¿")
                        
                        # æ·»åŠ ç”¨æˆ·åé¦ˆåŠŸèƒ½
                        st.markdown("---")
                        st.subheader("ğŸ’¬ åé¦ˆè¿™ä¸ªå›ç­”")
                        
                        col_fb1, col_fb2, col_fb3 = st.columns(3)
                        with col_fb1:
                            if st.button("ğŸ‘ å›ç­”å‡†ç¡®", use_container_width=True):
                                st.success("æ„Ÿè°¢æ‚¨çš„åé¦ˆï¼")
                        with col_fb2:
                            if st.button("ğŸ‘ å›ç­”ä¸å‡†ç¡®", use_container_width=True):
                                st.error("æŠ±æ­‰å›ç­”æœ‰è¯¯ï¼Œæˆ‘ä»¬ä¼šæ”¹è¿›ï¼")
                        with col_fb3:
                            if st.button("ğŸ¤” ä¸ç¡®å®š", use_container_width=True):
                                st.info("æ„Ÿè°¢åé¦ˆï¼Œæˆ‘ä»¬ä¼šæ£€æŸ¥è¿™ä¸ªé—®é¢˜ã€‚")

        # å¯¹è¯å†å²
        st.markdown("---")
        st.subheader("ğŸ“œ å¯¹è¯å†å²")

        if len(st.session_state.all_conversations) > 0:
            for i, conv in enumerate(st.session_state.all_conversations[-5:]):
                with st.expander(f"{conv['time']} - {conv['query'][:30]}..."):
                    col_a, col_b = st.columns([3, 1])
                    with col_a:
                        st.markdown(f"**ç”¨æˆ·é—®é¢˜:** {conv['query']}")
                        st.markdown(f"**å®¢æœå›å¤:** {conv['reply']}")
                    with col_b:
                        source_text = conv['source']
                        if "çŸ¥è¯†åº“" in source_text:
                            source_badge = "ğŸŸ¢ çŸ¥è¯†åº“"
                        elif "AIæ¨¡å‹" in source_text:
                            source_badge = "ğŸ”µ AIç”Ÿæˆ"
                        elif "ç³»ç»Ÿé¢„è®¾" in source_text:
                            source_badge = "ğŸŸ£ ç³»ç»Ÿé¢„è®¾"
                        else:
                            source_badge = f"ğŸŸ  {source_text}"
                        st.caption(f"æ¥æº: {source_badge}")
                        st.caption(f"è€—æ—¶: {conv['latency']:.2f}ç§’")
                        
                        # æ·»åŠ åˆ é™¤æŒ‰é’®
                        if st.button(f"ğŸ—‘ï¸ åˆ é™¤", key=f"delete_{i}"):
                            # ä»å¯¹è¯å†å²ä¸­åˆ é™¤
                            del st.session_state.all_conversations[i]
                            st.rerun()
        else:
            st.info("æš‚æ— å¯¹è¯å†å²ï¼Œè¯·å…ˆæé—®")

    with col2:
        st.subheader("ğŸ“Š ç³»ç»Ÿä¿¡æ¯")

        # çŸ¥è¯†åº“çŠ¶æ€
        if st.session_state.knowledge_df is not None:
            df = st.session_state.knowledge_df
            st.success(f"âœ… çŸ¥è¯†åº“å·²åŠ è½½")
            st.metric("çŸ¥è¯†æ¡ç›®", len(df))

            # æ˜¾ç¤ºçŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯
            with st.expander("ğŸ“‹ çŸ¥è¯†åº“è¯¦æƒ…"):
                # é—®é¢˜ç±»å‹åˆ†å¸ƒ
                if 'é—®é¢˜ç±»å‹' in df.columns:
                    st.write("**é—®é¢˜ç±»å‹åˆ†å¸ƒ:**")
                    type_counts = df['é—®é¢˜ç±»å‹'].value_counts()
                    for type_name, count in type_counts.items():
                        # åˆ›å»ºæ°´å¹³æ¡å½¢å›¾æ•ˆæœ
                        percent = count / len(df) * 100
                        st.progress(percent / 100, text=f"{type_name}: {count}æ¡ ({percent:.1f}%)")
                else:
                    st.write("çŸ¥è¯†åº“æœªæ ‡æ³¨é—®é¢˜ç±»å‹")

                # ç¤ºä¾‹é—®é¢˜å±•ç¤º
                st.write("**ç¤ºä¾‹é—®é¢˜:**")
                # ä¼˜å…ˆå±•ç¤ºä¸åŒç±»å‹çš„é—®é¢˜
                sample_size = min(5, len(df))
                if 'é—®é¢˜ç±»å‹' in df.columns and df['é—®é¢˜ç±»å‹'].nunique() > 1:
                    # å°è¯•ä»ä¸åŒç±»åˆ«å–æ ·
                    samples = []
                    for type_name in df['é—®é¢˜ç±»å‹'].unique():
                        type_samples = df[df['é—®é¢˜ç±»å‹'] == type_name].head(1)
                        samples.extend(type_samples['é—®é¢˜'].tolist())
                    samples = samples[:sample_size]
                else:
                    samples = df['é—®é¢˜'].sample(sample_size).tolist()

                for q in samples:
                    st.caption(f"â€¢ {q[:25]}..." if len(q) > 25 else f"â€¢ {q}")

                # æ˜¾ç¤ºè§„åˆ™åº“ä¿¡æ¯
                if st.session_state.rule_base is not None:
                    st.write("**è§„åˆ™åº“è¦†ç›–ç±»åˆ«:**")
                    rule_categories = list(st.session_state.rule_base.keys())
                    for category in rule_categories:
                        pattern_count = len(st.session_state.rule_base[category]["patterns"])
                        st.caption(f"â€¢ {category} ({pattern_count}ä¸ªå…³é”®è¯)")
                        
                # æ·»åŠ çŸ¥è¯†åº“å¯¼å‡ºåŠŸèƒ½
                st.markdown("---")
                if st.button("ğŸ“¥ å¯¼å‡ºçŸ¥è¯†åº“ç»Ÿè®¡", use_container_width=True):
                    # åˆ›å»ºç»Ÿè®¡DataFrame
                    stats_df = pd.DataFrame({
                        'æŒ‡æ ‡': ['æ€»é—®é¢˜æ•°', 'é—®é¢˜ç±»å‹æ•°', 'å¹³å‡å›ç­”é•¿åº¦'],
                        'æ•°å€¼': [
                            len(df),
                            df['é—®é¢˜ç±»å‹'].nunique() if 'é—®é¢˜ç±»å‹' in df.columns else 0,
                            df['æ ‡å‡†å›ç­”'].str.len().mean()
                        ]
                    })
                    st.dataframe(stats_df, use_container_width=True)
        else:
            st.warning("ğŸ“ ç­‰å¾…åŠ è½½çŸ¥è¯†åº“")
            st.info("è¯·ä¸Šä¼ åŒ…å«ä¸‰åˆ—(é—®é¢˜ã€æ ‡å‡†å›ç­”ã€é—®é¢˜ç±»å‹)çš„Excelæ–‡ä»¶")

        # è„±æ•æ¼”ç¤º
        st.markdown("---")
        st.subheader("ğŸ”’ è„±æ•æ¼”ç¤º")

        # ä½¿ç”¨session_stateå­˜å‚¨æµ‹è¯•æ–‡æœ¬
        if 'test_text' not in st.session_state:
            st.session_state.test_text = "æˆ‘çš„æ‰‹æœºæ˜¯15766265746, åœ°å€æ˜¯æ­å·å¸‚è¥¿æ¹–åŒºæ–‡ä¸‰è·¯"

        test_text = st.text_area(
            "è¾“å…¥æµ‹è¯•æ–‡æœ¬:",
            value=st.session_state.test_text,
            height=100,
            key="test_input"
        )

        # æ·»åŠ ä¸€ä¸ªæŒ‰é’®æ¥è§¦å‘è„±æ•
        col1, col2 = st.columns([3, 1])
        with col1:
            if st.button("è¿è¡Œè„±æ•æµ‹è¯•", type="primary"):
                st.session_state.test_text = test_text

                # ç›´æ¥æµ‹è¯•è„±æ•å‡½æ•°
                st.markdown("### æµ‹è¯•ç»“æœ")

                # 1. å…ˆæ˜¾ç¤ºåŸå§‹æ–‡æœ¬
                st.markdown("**åŸå§‹æ–‡æœ¬:**")
                st.code(test_text)

                # 2. è°ƒç”¨è„±æ•å‡½æ•°
                result = desensitize(test_text)

                # 3. æ˜¾ç¤ºè„±æ•ç»“æœ
                st.markdown("**è„±æ•ç»“æœ:**")
                st.code(result)

                # 4. æ˜¾ç¤ºå¯¹æ¯”
                if result != test_text:
                    st.success("âœ… è„±æ•æˆåŠŸ!")
                else:
                    st.error("âŒ è„±æ•å¤±è´¥! æ–‡æœ¬æ²¡æœ‰å˜åŒ–ã€‚")

        # ç»Ÿè®¡å›¾è¡¨
        st.markdown("---")
        st.subheader("ğŸ“ˆ æ€§èƒ½ç»Ÿè®¡")

        if len(st.session_state.all_conversations) > 0:
            fig = generate_statistics_chart()
            if fig:
                st.pyplot(fig)

            # ç®€å•ç»Ÿè®¡
            df_stats = pd.DataFrame(st.session_state.all_conversations)
            if not df_stats.empty:
                avg_latency = df_stats['latency'].mean()

                # æ–°çš„ç»Ÿè®¡é€»è¾‘ï¼šçŸ¥è¯†åº“å‘½ä¸­ vs AIç”Ÿæˆ vs ç³»ç»Ÿé¢„è®¾
                kb_count = len(df_stats[df_stats['source'].str.contains('çŸ¥è¯†åº“')])
                ai_count = len(df_stats[df_stats['source'].str.contains('AIæ¨¡å‹')])
                sys_count = len(df_stats[df_stats['source'].str.contains('ç³»ç»Ÿé¢„è®¾')])
                other_count = len(df_stats) - kb_count - ai_count - sys_count

                st.metric("å¹³å‡å“åº”æ—¶é—´", f"{avg_latency:.2f}ç§’")

                # æ˜¾ç¤ºå›ç­”æ¥æºåˆ†å¸ƒ
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("çŸ¥è¯†åº“å‘½ä¸­", kb_count)
                with col2:
                    st.metric("AIç”Ÿæˆ", ai_count)
                with col3:
                    st.metric("ç³»ç»Ÿé¢„è®¾", sys_count)

                # è®¡ç®—å‘½ä¸­ç‡
                if len(df_stats) > 0:
                    hit_rate = (kb_count + sys_count) / len(df_stats) * 100
                    st.progress(hit_rate / 100, text=f"çŸ¥è¯†åº“+é¢„è®¾å‘½ä¸­ç‡: {hit_rate:.1f}%")
                    
                # æ·»åŠ æ€§èƒ½å»ºè®®
                with st.expander("ğŸ“Š æ€§èƒ½åˆ†æå»ºè®®"):
                    if avg_latency > 2.0:
                        st.warning("âš ï¸ å¹³å‡å“åº”æ—¶é—´è¾ƒé•¿ï¼Œå»ºè®®:")
                        st.markdown("""
                        1. æ£€æŸ¥APIç½‘ç»œè¿æ¥
                        2. è€ƒè™‘ä½¿ç”¨æœ¬åœ°ç¼“å­˜
                        3. ä¼˜åŒ–çŸ¥è¯†åº“åŒ¹é…ç®—æ³•
                        """)
                    else:
                        st.success("âœ… å“åº”æ—¶é—´æ­£å¸¸")
                        
                    if hit_rate < 50:
                        st.warning(f"âš ï¸ çŸ¥è¯†åº“å‘½ä¸­ç‡è¾ƒä½ ({hit_rate:.1f}%)ï¼Œå»ºè®®:")
                        st.markdown("""
                        1. æ‰©å……çŸ¥è¯†åº“å†…å®¹
                        2. ä¼˜åŒ–å…³é”®è¯åŒ¹é…è§„åˆ™
                        3. æ·»åŠ æ›´å¤šç¤ºä¾‹é—®é¢˜
                        """)
                    else:
                        st.success(f"âœ… çŸ¥è¯†åº“å‘½ä¸­ç‡è‰¯å¥½ ({hit_rate:.1f}%)")

    # é¡µè„š
    st.markdown("---")
    st.caption("ğŸ’¡ æç¤º:è¿™æ˜¯ä¸€ä¸ªæ¼”ç¤ºç³»ç»Ÿ,å›å¤ä»…ä¾›å‚è€ƒã€‚æŠ€æœ¯å‚æ•°ç±»é—®é¢˜ä¼˜å…ˆä»çŸ¥è¯†åº“åŒ¹é…,å…¶ä»–é—®é¢˜ç”±AIç”Ÿæˆã€‚")
    st.caption("âš ï¸ å®é™…ä½¿ç”¨æ—¶è¯·ç¡®ä¿æ•°æ®å®‰å…¨å¹¶éµå®ˆå¹³å°è§„åˆ™ã€‚")


if __name__ == "__main__":
    main()


